[22:14:31,013][INFO][main][IgniteKernal] 

>>>    __________  ________________  
>>>   /  _/ ___/ |/ /  _/_  __/ __/  
>>>  _/ // (7 7    // /  / / / _/    
>>> /___/\___/_/|_/___/ /_/ /___/   
>>> 
>>> ver. 2.16.0#20231215-sha1:7bde6a42
>>> 2023 Copyright(C) Apache Software Foundation
>>> 
>>> Ignite documentation: https://ignite.apache.org

[22:14:31,023][INFO][main][IgniteKernal] Config URL: file:/opt/ignite/apache-ignite/config/default-config.xml
[22:14:31,055][INFO][main][IgniteKernal] IgniteConfiguration [igniteInstanceName=null, pubPoolSize=12, svcPoolSize=12, callbackPoolSize=12, stripedPoolSize=12, sysPoolSize=12, mgmtPoolSize=4, dataStreamerPoolSize=12, utilityCachePoolSize=12, utilityCacheKeepAliveTime=60000, p2pPoolSize=2, qryPoolSize=12, buildIdxPoolSize=3, igniteHome=/opt/ignite/apache-ignite, igniteWorkDir=/storage, mbeanSrv=com.sun.jmx.mbeanserver.JmxMBeanServer@32a068d1, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, marsh=BinaryMarshaller [], marshLocJobs=false, p2pEnabled=false, netTimeout=5000, netCompressionLevel=1, sndRetryDelay=1000, sndRetryCnt=3, metricsHistSize=10000, metricsUpdateFreq=2000, metricsExpTime=9223372036854775807, discoSpi=TcpDiscoverySpi [addrRslvr=null, addressFilter=null, sockTimeout=0, ackTimeout=0, marsh=null, reconCnt=10, reconDelay=2000, maxAckTimeout=600000, soLinger=0, forceSrvMode=false, clientReconnectDisabled=false, internalLsnr=null, skipAddrsRandomization=false], segPlc=USE_FAILURE_HANDLER, segResolveAttempts=2, waitForSegOnStart=true, allResolversPassReq=true, segChkFreq=10000, commSpi=TcpCommunicationSpi [connectGate=org.apache.ignite.spi.communication.tcp.internal.ConnectGateway@5dda768f, ctxInitLatch=java.util.concurrent.CountDownLatch@7a8c8dcf[Count = 1], stopping=false, clientPool=null, nioSrvWrapper=null, stateProvider=null], evtSpi=org.apache.ignite.spi.eventstorage.NoopEventStorageSpi@24269709, colSpi=NoopCollisionSpi [], deploySpi=LocalDeploymentSpi [], indexingSpi=org.apache.ignite.spi.indexing.noop.NoopIndexingSpi@1ff4931d, addrRslvr=null, encryptionSpi=org.apache.ignite.spi.encryption.noop.NoopEncryptionSpi@65e98b1c, tracingSpi=org.apache.ignite.spi.tracing.NoopTracingSpi@61322f9d, clientMode=false, rebalanceThreadPoolSize=3, rebalanceTimeout=10000, rebalanceBatchesPrefetchCnt=3, rebalanceThrottle=0, rebalanceBatchSize=524288, txCfg=TransactionConfiguration [txSerEnabled=false, dfltIsolation=REPEATABLE_READ, dfltConcurrency=PESSIMISTIC, dfltTxTimeout=0, txTimeoutOnPartitionMapExchange=0, pessimisticTxLogSize=0, pessimisticTxLogLinger=10000, tmLookupClsName=null, txManagerFactory=null, useJtaSync=false], cacheSanityCheckEnabled=true, discoStartupDelay=60000, deployMode=SHARED, p2pMissedCacheSize=100, locHost=null, timeSrvPortBase=31100, timeSrvPortRange=100, failureDetectionTimeout=10000, sysWorkerBlockedTimeout=null, clientFailureDetectionTimeout=30000, metricsLogFreq=60000, connectorCfg=ConnectorConfiguration [jettyPath=null, host=null, port=11211, noDelay=true, directBuf=false, sndBufSize=32768, rcvBufSize=32768, idleQryCurTimeout=600000, idleQryCurCheckFreq=60000, sndQueueLimit=0, selectorCnt=4, idleTimeout=7000, sslEnabled=false, sslClientAuth=false, sslFactory=null, portRange=100, threadPoolSize=12, msgInterceptor=null], odbcCfg=null, warmupClos=null, atomicCfg=AtomicConfiguration [seqReserveSize=1000, cacheMode=PARTITIONED, backups=1, aff=null, grpName=null], classLdr=null, sslCtxFactory=null, platformCfg=null, binaryCfg=null, memCfg=null, pstCfg=null, dsCfg=DataStorageConfiguration [pageSize=0, concLvl=0, sysDataRegConf=org.apache.ignite.configuration.SystemDataRegionConfiguration@6200f9cb, dfltDataRegConf=DataRegionConfiguration [name=default, maxSize=3324652748, initSize=268435456, swapPath=null, pageEvictionMode=DISABLED, pageReplacementMode=CLOCK, evictionThreshold=0.9, emptyPagesPoolSize=100, metricsEnabled=false, metricsSubIntervalCount=5, metricsRateTimeInterval=60000, persistenceEnabled=false, checkpointPageBufSize=0, lazyMemoryAllocation=true, warmUpCfg=null, memoryAllocator=null, cdcEnabled=false], dataRegions=null, storagePath=null, checkpointFreq=180000, lockWaitTime=10000, checkpointThreads=4, checkpointWriteOrder=SEQUENTIAL, walHistSize=20, maxWalArchiveSize=1073741824, walSegments=10, walSegmentSize=67108864, walPath=db/wal, walArchivePath=db/wal/archive, cdcWalPath=db/wal/cdc, cdcWalDirMaxSize=0, metricsEnabled=false, walMode=LOG_ONLY, walTlbSize=131072, walBuffSize=0, walFlushFreq=2000, walFsyncDelay=1000, walRecordIterBuffSize=67108864, alwaysWriteFullPages=false, fileIOFactory=org.apache.ignite.internal.processors.cache.persistence.file.AsyncFileIOFactory@2de23121, metricsSubIntervalCnt=5, metricsRateTimeInterval=60000, walAutoArchiveAfterInactivity=-1, walForceArchiveTimeout=-1, writeThrottlingEnabled=false, walCompactionEnabled=false, walCompactionLevel=1, checkpointReadLockTimeout=null, walPageCompression=DISABLED, walPageCompressionLevel=null, dfltWarmUpCfg=null, encCfg=org.apache.ignite.configuration.EncryptionConfiguration@4988d8b8, defragmentationThreadPoolSize=4, minWalArchiveSize=-1, memoryAllocator=null], snapshotPath=snapshots, snapshotThreadPoolSize=4, activeOnStart=true, activeOnStartPropSetFlag=false, autoActivation=true, autoActivationPropSetFlag=false, clusterStateOnStart=null, sqlConnCfg=null, cliConnCfg=ClientConnectorConfiguration [host=null, port=10800, portRange=100, sockSndBufSize=0, sockRcvBufSize=0, tcpNoDelay=true, maxOpenCursorsPerConn=128, threadPoolSize=12, selectorCnt=6, idleTimeout=0, handshakeTimeout=10000, jdbcEnabled=true, odbcEnabled=true, thinCliEnabled=true, sslEnabled=false, useIgniteSslCtxFactory=true, sslClientAuth=false, sslCtxFactory=null, thinCliCfg=ThinClientConfiguration [maxActiveTxPerConn=100, maxActiveComputeTasksPerConn=0, sendServerExcStackTraceToClient=false], sesOutboundMsgQueueLimit=0], mvccVacuumThreadCnt=2, mvccVacuumFreq=5000, authEnabled=false, failureHnd=null, commFailureRslvr=null, sqlCfg=SqlConfiguration [longQryWarnTimeout=3000, dfltQryTimeout=0, sqlQryHistSize=1000, validationEnabled=false], asyncContinuationExecutor=null]
[22:14:31,056][INFO][main][IgniteKernal] OS: Linux 5.15.153.1-microsoft-standard-WSL2 amd64
[22:14:31,056][INFO][main][IgniteKernal] OS user: root
[22:14:31,059][INFO][main][IgniteKernal] PID: 1
[22:14:31,060][INFO][main][IgniteKernal] Language runtime: Java Platform API Specification ver. 1.8
[22:14:31,060][INFO][main][IgniteKernal] VM information: OpenJDK Runtime Environment 1.8.0_392-b08 Temurin OpenJDK 64-Bit Server VM 25.392-b08
[22:14:31,060][INFO][main][IgniteKernal] VM total memory: 0.96GB
[22:14:31,060][INFO][main][IgniteKernal] Remote Management [restart: off, REST: on, JMX (remote: off)]
[22:14:31,061][INFO][main][IgniteKernal] Logger: JavaLogger [quiet=true, config=null]
[22:14:31,061][INFO][main][IgniteKernal] IGNITE_HOME=/opt/ignite/apache-ignite
[22:14:31,061][INFO][main][IgniteKernal] VM arguments: [-XX:+AggressiveOpts, -Xms1g, -Xmx1g, -XX:MaxMetaspaceSize=256m, -DIGNITE_HOME=/opt/ignite/apache-ignite]
[22:14:31,062][INFO][main][IgniteKernal] System cache's DataRegion size is configured to 40 MB. Use DataStorageConfiguration.systemRegionInitialSize property to change the setting.
[22:14:31,062][INFO][main][IgniteKernal] Configured caches [in 'sysMemPlc' dataRegion: ['ignite-sys-cache']]
[22:14:31,062][WARNING][main][IgniteKernal] Please set system property '-Djava.net.preferIPv4Stack=true' to avoid possible problems in mixed environments.
[22:14:31,062][INFO][main][IgniteKernal] 3-rd party licenses can be found at: /opt/ignite/apache-ignite/libs/licenses
[22:14:31,153][INFO][main][IgnitePluginProcessor] Configured plugins:
[22:14:31,154][INFO][main][IgnitePluginProcessor]   ^-- None
[22:14:31,154][INFO][main][IgnitePluginProcessor] 
[22:14:31,157][INFO][main][FailureProcessor] Configured failure handler: [hnd=StopNodeOrHaltFailureHandler [tryStop=false, timeout=0, super=AbstractFailureHandler [ignoredFailureTypes=UnmodifiableSet [SYSTEM_WORKER_BLOCKED, SYSTEM_CRITICAL_OPERATION_TIMEOUT]]]]
[22:14:31,485][INFO][main][TcpCommunicationSpi] Successfully bound communication NIO server to TCP port [port=47100, locHost=0.0.0.0/0.0.0.0, selectorsCnt=6, selectorSpins=0, pairedConn=false]
[22:14:31,485][WARNING][main][TcpCommunicationSpi] Message queue limit is set to 0 which may lead to potential OOMEs when running cache operations in FULL_ASYNC or PRIMARY_SYNC modes due to message queues growth on sender and receiver sides.
[22:14:31,510][INFO][main][GridCollisionManager] Collision resolution is disabled (all jobs will be activated upon arrival).
[22:14:31,697][INFO][main][TcpDiscoverySpi] Successfully bound to TCP port [port=47500, localHost=0.0.0.0/0.0.0.0, locNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[22:14:31,699][INFO][main][GridLocalConfigManager] Resolved page store work directory: /storage/db/0_0_0_0_0_0_0_1_lo_127_0_0_1_172_22_0_2_47500
[22:14:31,731][INFO][main][IgniteCacheDatabaseSharedManager] Configured data regions initialized successfully [total=4]
[22:14:31,816][WARNING][main][IgniteH2Indexing] Serialization of Java objects in H2 was enabled.
[22:14:31,968][INFO][main][ClientListenerProcessor] Client connector processor has started on TCP port 10800
[22:14:32,073][INFO][main][GridTcpRestProtocol] Command protocol successfully started [name=TCP binary, host=0.0.0.0/0.0.0.0, port=11211]
[22:14:32,125][INFO][main][IgniteKernal] Non-loopback local IPs: 172.22.0.2, fe80:0:0:0:42:acff:fe16:2%eth0
[22:14:32,125][INFO][main][IgniteKernal] Enabled local MACs: 0242AC160002
[22:14:32,131][INFO][main][ClusterProcessor] Cluster ID and tag has been read from metastorage: null
[22:14:32,138][INFO][main][IgniteClusterImpl] Shutdown policy was updated [oldVal=null, newVal=null]
[22:14:32,140][INFO][main][IgniteStatisticsManagerImpl] Statistics usage state was changed from null to null
[22:14:32,152][WARNING][main][TcpDiscoveryMulticastIpFinder] TcpDiscoveryMulticastIpFinder has no pre-configured addresses (it is recommended in production to specify at least one address in TcpDiscoveryMulticastIpFinder.getAddresses() configuration property)
[22:14:33,395][INFO][disco-notifier-worker-#56][GridClusterStateProcessor] Received activate cluster request with BaselineTopology[id=0] initiator node ID: 9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[22:14:33,397][INFO][disco-notifier-worker-#56][GridClusterStateProcessor] Started state transition: activate cluster
[22:14:33,398][INFO][disco-notifier-worker-#56][GridClusterStateProcessor] Received state change finish message: ACTIVE
[22:14:33,398][INFO][disco-notifier-worker-#56][GridClusterStateProcessor] Cluster state was changed from ACTIVE to ACTIVE
[22:14:33,399][INFO][disco-notifier-worker-#56][MvccProcessorImpl] Assigned mvcc coordinator [crd=MvccCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, ver=1727216073386, local=true, initialized=false]]
[22:14:33,416][INFO][sys-#62][ClusterProcessor] Writing cluster ID and tag to metastorage on ready for write ClusterIdAndTag [id=3cf12d8d-6069-4fb2-8c46-8adba4b89aea, tag=musing_cannon]
[22:14:33,444][INFO][disco-notifier-worker-#56][ClusterProcessor] Cluster tag will be set to new value: musing_cannon, previous value was: null
[22:14:33,448][INFO][disco-notifier-worker-#56][DistributedBaselineConfiguration] Baseline parameter 'baselineAutoAdjustEnabled' was changed from 'null' to 'true'
[22:14:33,451][INFO][disco-notifier-worker-#56][DistributedBaselineConfiguration] Baseline parameter 'baselineAutoAdjustTimeout' was changed from 'null' to '0'
[22:14:33,452][INFO][disco-notifier-worker-#56][IgniteTxManager] Transactions parameter 'longOperationsDumpTimeout' was changed from 'null' to '60000'
[22:14:33,454][INFO][disco-notifier-worker-#56][IgniteTxManager] Transactions parameter 'longTransactionTimeDumpThreshold' was changed from 'null' to '0'
[22:14:33,455][INFO][disco-notifier-worker-#56][IgniteTxManager] Transactions parameter 'transactionTimeDumpSamplesCoefficient' was changed from 'null' to '0.0'
[22:14:33,457][INFO][disco-notifier-worker-#56][IgniteTxManager] Transactions parameter 'longTransactionTimeDumpSamplesPerSecondLimit' was changed from 'null' to '5'
[22:14:33,458][INFO][disco-notifier-worker-#56][IgniteTxManager] Transactions parameter 'collisionsDumpInterval' was changed from 'null' to '1000'
[22:14:33,465][INFO][disco-notifier-worker-#56][IgniteTxManager] Transactions parameter 'txOwnerDumpRequestsAllowed' was changed from 'null' to 'true'
[22:14:33,469][INFO][disco-notifier-worker-#56][IgniteSnapshotManager] The snapshot transfer rate is not limited.
[22:14:33,471][INFO][disco-notifier-worker-#56][IgniteH2Indexing] SQL parameter 'sql.defaultQueryTimeout' was changed from 'null' to '0'
[22:14:33,473][INFO][disco-notifier-worker-#56][IgniteH2Indexing] SQL parameter 'sql.disabledFunctions' was changed from 'null' to '[FILE_WRITE, CANCEL_SESSION, MEMORY_USED, CSVREAD, LINK_SCHEMA, MEMORY_FREE, FILE_READ, CSVWRITE, SESSION_ID, LOCK_MODE]'
[22:14:33,597][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], crd=true, evt=NODE_JOINED, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=null, allowMerge=false, exchangeFreeSwitch=false]
[22:14:33,609][INFO][exchange-worker-#63][IgniteCacheDatabaseSharedManager] Data Regions Started: 4
[22:14:33,611][INFO][exchange-worker-#63][msg] Components activation performed in 13 ms.
[22:14:33,686][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=ignite-sys-cache, id=-2100569601, dataRegionName=sysMemPlc, mode=REPLICATED, atomicity=TRANSACTIONAL, backups=2147483647]
[22:14:33,695][INFO][exchange-worker-#63][GridCacheProcessor] Starting caches on local join performed in 81 ms.
[22:14:33,704][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Skipped waiting for partitions release future (local node is joining) [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=0]]
[22:14:33,757][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=0]]
[22:14:33,772][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], err=null, rebalanced=true, wasRebalanced=false]
[22:14:33,780][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=ignite-sys-cache, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[22:14:33,784][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], evt=NODE_JOINED, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=0]]
[22:14:33,785][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], stage="Waiting in exchange queue" (186 ms), stage="Exchange parameters initialization" (2 ms), stage="Components activation" (13 ms), stage="Determine exchange type" (92 ms), stage="Preloading notification" (0 ms), stage="After states restored callback" (52 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (1 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (10 ms), stage="Full message sending" (0 ms), stage="State finish message sending" (0 ms), stage="Exchange done" (12 ms), stage="Total time" (369 ms)]
[22:14:33,785][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], stage="Coordinator affinity cache init [grp=ignite-sys-cache]" (85 ms) (parent=Determine exchange type), stage="First node affinity initialization (node join) [grp=ignite-sys-cache]" (5 ms) (parent=Determine exchange type)]
[22:14:33,792][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=0], crd=true]
[22:14:33,794][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=0], force=false, evt=NODE_JOINED, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[22:14:33,818][INFO][main][IgniteKernal] Security status [authentication=off, sandbox=off, tls/ssl=off]
[22:14:33,818][INFO][main][IgniteKernal] Performance suggestions for grid  (fix if possible)
[22:14:33,818][INFO][main][IgniteKernal] To disable, set -DIGNITE_PERFORMANCE_SUGGESTIONS_DISABLED=true
[22:14:33,818][INFO][main][IgniteKernal]   ^-- Switch to the most recent 11 JVM version
[22:14:33,818][INFO][main][IgniteKernal]   ^-- Enable G1 Garbage Collector (add '-XX:+UseG1GC' to JVM options)
[22:14:33,818][INFO][main][IgniteKernal]   ^-- Set max direct memory size if getting 'OOME: Direct buffer memory' (add '-XX:MaxDirectMemorySize=<size>[g|G|m|M|k|K]' to JVM options)
[22:14:33,818][INFO][main][IgniteKernal]   ^-- Speed up flushing of dirty pages by OS (alter vm.dirty_writeback_centisecs and vm.dirty_expire_centisecs parameters by setting to 500)
[22:14:33,818][INFO][main][IgniteKernal]   ^-- Reduce pages swapping ratio (set vm.swappiness=10 or less)
[22:14:33,819][INFO][main][IgniteKernal] Refer to this page for more performance suggestions: https://ignite.apache.org/docs/latest/perf-and-troubleshooting/memory-tuning
[22:14:33,819][INFO][main][IgniteKernal] 
[22:14:33,819][INFO][main][IgniteKernal] 

>>> +-----------------------------------------------------------------------+
>>> Ignite ver. 2.16.0#20231215-sha1:7bde6a42b7fda05f8058350d30d67e57ada216d0
>>> +-----------------------------------------------------------------------+
>>> OS name: Linux 5.15.153.1-microsoft-standard-WSL2 amd64
>>> CPU(s): 12
>>> Heap: 1.0GB
>>> VM name: 1@ignite_host
>>> Local node [ID=9A74D0AE-7716-4F6D-AA69-AD70646E6D2B, order=1, clientMode=false]
>>> Local node addresses: [ignite_host/0:0:0:0:0:0:0:1%lo, /127.0.0.1, /172.22.0.2]
>>> Local ports: TCP:10800 TCP:11211 TCP:47100 UDP:47400 TCP:47500 
>>> +-----------------------------------------------------------------------+

[22:14:33,821][INFO][main][GridDiscoveryManager] Topology snapshot [ver=1, locNode=9a74d0ae, servers=1, clients=0, state=ACTIVE, CPUs=12, offheap=3.1GB, heap=1.0GB, aliveNodes=[TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, isClient=false, ver=2.16.0#20231215-sha1:7bde6a42]]]
[22:14:33,821][INFO][main][GridDiscoveryManager]   ^-- Baseline [id=0, size=1, online=1, offline=0]
[22:14:33,821][INFO][main][G] Node started : [stage="Configure system pool" (87 ms),stage="Start managers" (536 ms),stage="Configure binary metadata" (38 ms),stage="Start processors" (540 ms),stage="Init metastore" (18 ms),stage="Finish recovery" (0 ms),stage="Join topology" (1258 ms),stage="Await transition" (25 ms),stage="Await exchange" (396 ms),stage="Total time" (2898 ms)]
[22:14:41,054][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=DynamicCacheChangeBatch [id=9c3b9162291-b833fd4c-7c0a-44a3-9bac-3b4e16c7e0df, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=map_metadata, hasCfg=true, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[map_metadata], stopCaches=null, startGrps=[map_metadata], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[22:14:41,067][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=map_metadata, id=2080329394, dataRegionName=default, mode=PARTITIONED, atomicity=ATOMIC, backups=0]
[22:14:41,084][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[22:14:41,087][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1]]]]
[22:14:41,087][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], waitTime=0ms, futInfo=NA, mode=LOCAL]
[22:14:41,160][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=1]]
[22:14:41,177][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], err=null, rebalanced=true, wasRebalanced=true]
[22:14:41,179][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=map_metadata, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[22:14:41,179][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1]]
[22:14:41,180][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (1 ms), stage="Update caches registry" (1 ms), stage="Start caches" (17 ms), stage="Affinity initialization on cache group start" (8 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (3 ms), stage="Wait partitions release latch [latch=exchange]" (1 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (71 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (1 ms), stage="Validate partitions states" (2 ms), stage="Apply update counters" (3 ms), stage="Full message preparing" (9 ms), stage="Full message sending" (0 ms), stage="Exchange done" (2 ms), stage="Total time" (119 ms)]
[22:14:41,180][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], stage="Affinity initialization on cache group start [grp=map_metadata]" (8 ms) (parent=Affinity initialization on cache group start)]
[22:14:41,180][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=1], crd=true]
[22:14:41,183][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=1], force=false, evt=DISCOVERY_CUSTOM_EVT, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[22:14:41,190][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=DynamicCacheChangeBatch [id=fc3b9162291-b833fd4c-7c0a-44a3-9bac-3b4e16c7e0df, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=map, hasCfg=true, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[map], stopCaches=null, startGrps=[map], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[22:14:41,193][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=map, id=107868, dataRegionName=default, mode=PARTITIONED, atomicity=ATOMIC, backups=0]
[22:14:41,197][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[22:14:41,198][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2]]]]
[22:14:41,198][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], waitTime=0ms, futInfo=NA, mode=LOCAL]
[22:14:41,223][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=2]]
[22:14:41,228][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], err=null, rebalanced=true, wasRebalanced=true]
[22:14:41,232][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=map, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[22:14:41,233][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2]]
[22:14:41,234][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (3 ms), stage="Affinity initialization on cache group start" (3 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (24 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (0 ms), stage="Full message preparing" (2 ms), stage="Full message sending" (0 ms), stage="Exchange done" (5 ms), stage="Total time" (38 ms)]
[22:14:41,234][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], stage="Affinity initialization on cache group start [grp=map]" (3 ms) (parent=Affinity initialization on cache group start)]
[22:14:41,237][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=2], crd=true]
[22:14:41,241][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=2], force=false, evt=DISCOVERY_CUSTOM_EVT, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[22:15:33,833][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:01:00.017]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.31%, GC=0%]
    ^-- Heap [used=113MB, free=88.39%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=12, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:15:43,569][INFO][ignite-update-notifier-timer][GridUpdateNotifier] Update status is not available.
[22:16:33,839][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:02:00.022]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.2%, avgLoad=0.23%, GC=0%]
    ^-- Heap [used=117MB, free=88.02%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=6, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:17:33,843][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:03:00.025]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.22%, GC=0%]
    ^-- Heap [used=122MB, free=87.56%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:18:33,848][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:04:00.027]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.2%, GC=0%]
    ^-- Heap [used=130MB, free=86.71%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:19:33,840][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:05:00.027]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.19%, GC=0%]
    ^-- Heap [used=134MB, free=86.32%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:20:33,845][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:06:00.032]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.19%, GC=0%]
    ^-- Heap [used=138MB, free=85.86%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:21:33,846][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:07:00.032]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.18%, GC=0%]
    ^-- Heap [used=142MB, free=85.45%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:22:33,850][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:08:00.036]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.18%, GC=0%]
    ^-- Heap [used=146MB, free=85.06%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:23:33,853][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:09:00.037]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.18%, GC=0%]
    ^-- Heap [used=151MB, free=84.6%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:24:33,859][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:10:00.045]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.17%, GC=0%]
    ^-- Heap [used=155MB, free=84.19%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:25:33,859][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:11:00.045]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.17%, GC=0%]
    ^-- Heap [used=159MB, free=83.77%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:26:33,867][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:12:00.052]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.16%, GC=0%]
    ^-- Heap [used=163MB, free=83.31%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:27:33,875][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:13:00.062]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.16%, GC=0%]
    ^-- Heap [used=167MB, free=82.9%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:28:33,884][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:14:00.063]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.16%, GC=0%]
    ^-- Heap [used=171MB, free=82.49%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:29:33,895][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:15:00.078]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.16%, GC=0%]
    ^-- Heap [used=176MB, free=82.04%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:30:33,895][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:16:00.080]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.15%, GC=0%]
    ^-- Heap [used=180MB, free=81.59%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:31:33,902][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:17:00.089]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.15%, GC=0%]
    ^-- Heap [used=185MB, free=81.15%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:32:33,911][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:18:00.090]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.15%, GC=0%]
    ^-- Heap [used=189MB, free=80.74%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:33:33,916][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:19:00.097]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.15%, GC=0%]
    ^-- Heap [used=193MB, free=80.31%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:34:33,916][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:20:00.099]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.15%, GC=0%]
    ^-- Heap [used=197MB, free=79.85%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:35:33,919][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:21:00.103]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.14%, GC=0%]
    ^-- Heap [used=204MB, free=79.18%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:36:33,925][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:22:00.108]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.14%, GC=0%]
    ^-- Heap [used=208MB, free=78.77%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:37:33,927][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:23:00.113]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.14%, GC=0%]
    ^-- Heap [used=213MB, free=78.29%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:38:33,936][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:24:00.116]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.14%, GC=0%]
    ^-- Heap [used=216MB, free=77.92%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:39:33,938][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:25:00.123]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.14%, GC=0%]
    ^-- Heap [used=220MB, free=77.49%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:40:33,944][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:26:00.126]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=225MB, free=77.02%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:41:33,946][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:27:00.132]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=229MB, free=76.65%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:42:33,948][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:28:00.134]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=233MB, free=76.2%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:43:33,956][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:29:00.139]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=237MB, free=75.79%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:44:33,962][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:30:00.149]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=241MB, free=75.36%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:45:33,972][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:31:00.156]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=246MB, free=74.93%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:46:33,976][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:32:00.161]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=250MB, free=74.52%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:47:33,978][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:33:00.161]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=254MB, free=74.07%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:48:33,979][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:34:00.166]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=258MB, free=73.67%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:49:33,981][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:35:00.167]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=262MB, free=73.24%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:50:33,982][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:36:00.168]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=267MB, free=72.77%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:51:33,989][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:37:00.170]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=271MB, free=72.36%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:52:33,993][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:38:00.175]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=274MB, free=72.02%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:53:33,996][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:39:00.179]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=45MB, free=95.4%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:54:33,998][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:40:00.182]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=48MB, free=95.1%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:55:34,000][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:41:00.183]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.03%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=50MB, free=94.84%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:56:34,000][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:42:00.184]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=54MB, free=94.4%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:57:34,006][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:43:00.187]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=58MB, free=94.09%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:58:34,008][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:44:00.190]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=60MB, free=93.82%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[22:59:34,011][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:45:00.191]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=63MB, free=93.57%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:00:34,013][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:46:00.199]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=65MB, free=93.31%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:01:34,019][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:47:00.204]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=68MB, free=93.02%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:02:34,020][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:48:00.207]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=71MB, free=92.72%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:03:34,020][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:49:00.207]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=73MB, free=92.5%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:04:34,026][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:50:00.209]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=76MB, free=92.23%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:05:34,030][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:51:00.216]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.07%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=79MB, free=91.91%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:06:34,032][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:52:00.216]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=82MB, free=91.63%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:07:34,039][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=00:53:00.218]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=84MB, free=91.35%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:34:21,803][WARNING][jvm-pause-detector-worker][IgniteKernal] Possible too long JVM pause: 1573622 milliseconds.
[23:34:21,816][SEVERE][tcp-disco-msg-worker-[crd]-#2-#57][G] Blocked system-critical thread has been detected. This can lead to cluster-wide undefined behaviour [workerName=ttl-cleanup-worker, threadName=ttl-cleanup-worker-#80, blockedFor=1573s]
[23:34:21,828][WARNING][tcp-disco-msg-worker-[crd]-#2-#57][] Possible failure suppressed accordingly to a configured handler [hnd=StopNodeOrHaltFailureHandler [tryStop=false, timeout=0, super=AbstractFailureHandler [ignoredFailureTypes=UnmodifiableSet [SYSTEM_WORKER_BLOCKED, SYSTEM_CRITICAL_OPERATION_TIMEOUT]]], failureCtx=FailureContext [type=SYSTEM_WORKER_BLOCKED, err=class o.a.i.IgniteException: GridWorker [name=ttl-cleanup-worker, igniteInstanceName=null, finished=false, heartbeatTs=1727219287904]]]
class org.apache.ignite.IgniteException: GridWorker [name=ttl-cleanup-worker, igniteInstanceName=null, finished=false, heartbeatTs=1727219287904]
	at java.lang.Thread.sleep(Native Method)
	at org.apache.ignite.internal.util.IgniteUtils.sleep(IgniteUtils.java:8394)
	at org.apache.ignite.internal.processors.cache.GridCacheSharedTtlCleanupManager$CleanupWorker.body(GridCacheSharedTtlCleanupManager.java:216)
	at org.apache.ignite.internal.util.worker.GridWorker.run(GridWorker.java:125)
	at java.lang.Thread.run(Thread.java:750)
[23:34:21,830][WARNING][tcp-disco-msg-worker-[crd]-#2-#57][FailureProcessor] No deadlocked threads detected.
[23:34:21,904][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:19:48.089]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.33%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=92MB, free=90.62%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=9, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:34:21,927][WARNING][tcp-disco-msg-worker-[crd]-#2-#57][FailureProcessor] Thread dump at 2024/09/24 23:34:21 GMT
Thread [name="sys-#506", id=522, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4988e8f, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-#505", id=521, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4988e8f, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-#504", id=520, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4988e8f, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-#503", id=519, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4988e8f, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-#502", id=518, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4988e8f, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="stat-mgmt-#501", id=517, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@317d3cc3, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-#500", id=516, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4988e8f, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-#499", id=515, state=TIMED_WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@4988e8f, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1073)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="client-connector-#87", id=103, state=WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@51f4afb0, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="client-connector-#86", id=102, state=WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@51f4afb0, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="client-connector-#85", id=101, state=WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@51f4afb0, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="client-connector-#83", id=99, state=WAITING, blockCnt=0, waitCnt=2]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@51f4afb0, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="ttl-cleanup-worker-#80", id=96, state=TIMED_WAITING, blockCnt=0, waitCnt=6412]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.i.util.IgniteUtils.sleep(IgniteUtils.java:8394)
        at o.a.i.i.processors.cache.GridCacheSharedTtlCleanupManager$CleanupWorker.body(GridCacheSharedTtlCleanupManager.java:216)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="client-connector-#78", id=94, state=WAITING, blockCnt=0, waitCnt=2]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@51f4afb0, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="client-connector-#77", id=93, state=WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@51f4afb0, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at java.util.concurrent.ThreadPoolExecutor.getTask(ThreadPoolExecutor.java:1074)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1134)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="session-timeout-worker-#49", id=62, state=TIMED_WAITING, blockCnt=0, waitCnt=3214]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.i.processors.rest.GridRestProcessor$4.body(GridRestProcessor.java:510)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="services-deployment-worker-#76", id=91, state=WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5491910, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at o.a.i.i.processors.service.ServiceDeploymentManager$ServicesDeploymentWorker.body(ServiceDeploymentManager.java:466)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-client-listener-5-#48", id=61, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@456513c0
        - locked java.util.Collections$UnmodifiableSet@1da6a48b
        - locked sun.nio.ch.EPollSelectorImpl@69db01a0
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-client-listener-4-#47", id=60, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@24970412
        - locked java.util.Collections$UnmodifiableSet@4901e853
        - locked sun.nio.ch.EPollSelectorImpl@61ab9f04
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-client-listener-3-#46", id=59, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@504c4490
        - locked java.util.Collections$UnmodifiableSet@4c676d1f
        - locked sun.nio.ch.EPollSelectorImpl@a6247b0
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-client-listener-2-#45", id=58, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@370cba47
        - locked java.util.Collections$UnmodifiableSet@55600f2
        - locked sun.nio.ch.EPollSelectorImpl@72ae8ad2
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-client-listener-1-#44", id=57, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@6a691cf0
        - locked java.util.Collections$UnmodifiableSet@38655d78
        - locked sun.nio.ch.EPollSelectorImpl@d019b16
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-client-listener-0-#43", id=56, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@bff787e
        - locked java.util.Collections$UnmodifiableSet@29d36b6d
        - locked sun.nio.ch.EPollSelectorImpl@3b4f6db2
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="nio-acceptor-client-listener-#75", id=90, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked sun.nio.ch.Util$3@3a9788e6
        - locked java.util.Collections$UnmodifiableSet@4a5b2b42
        - locked sun.nio.ch.EPollSelectorImpl@78e1a967
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$GridNioAcceptWorker.accept(GridNioServer.java:3093)
        at o.a.i.i.util.nio.GridNioServer$GridNioAcceptWorker.body(GridNioServer.java:3041)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="exchange-worker-#63", id=78, state=TIMED_WAITING, blockCnt=0, waitCnt=649]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@38037934, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:522)
        at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:684)
        at o.a.i.i.processors.cache.GridCachePartitionExchangeManager$ExchangeWorker.body0(GridCachePartitionExchangeManager.java:3243)
        at o.a.i.i.processors.cache.GridCachePartitionExchangeManager$ExchangeWorker.body(GridCachePartitionExchangeManager.java:3172)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="ignite-update-notifier-timer", id=77, state=TIMED_WAITING, blockCnt=0, waitCnt=62]
    Lock [object=java.util.TaskQueue@3ed5066a, ownerName=null, ownerId=-1]
        at java.lang.Object.wait(Native Method)
        at java.util.TimerThread.mainLoop(Timer.java:552)
        at java.util.TimerThread.run(Timer.java:505)

Thread [name="upd-ver-checker", id=76, state=TIMED_WAITING, blockCnt=0, waitCnt=642]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.i.processors.cluster.GridUpdateNotifier$1.run(GridUpdateNotifier.java:115)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="disco-event-worker-#61", id=74, state=WAITING, blockCnt=1, waitCnt=1633]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@2d472bc9, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at o.a.i.i.managers.discovery.GridDiscoveryManager$DiscoveryWorker.body0(GridDiscoveryManager.java:3089)
        at o.a.i.i.managers.discovery.GridDiscoveryManager$DiscoveryWorker.body(GridDiscoveryManager.java:3060)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="tcp-disco-ip-finder-cleaner-#5-#60", id=73, state=TIMED_WAITING, blockCnt=0, waitCnt=105]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.spi.discovery.tcp.ServerImpl$IpFinderCleaner.body(ServerImpl.java:2241)
        at o.a.i.spi.IgniteSpiThread.run(IgniteSpiThread.java:58)

Thread [name="tcp-disco-multicast-addr-sender-#4-#59", id=72, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at java.net.PlainDatagramSocketImpl.receive0(Native Method)
        - locked java.net.PlainDatagramSocketImpl@58981597
        at java.net.AbstractPlainDatagramSocketImpl.receive(AbstractPlainDatagramSocketImpl.java:143)
        - locked java.net.PlainDatagramSocketImpl@58981597
        at java.net.DatagramSocket.receive(DatagramSocket.java:812)
        - locked java.net.DatagramPacket@7bf10d69
        - locked java.net.MulticastSocket@6d01a22b
        at o.a.i.spi.discovery.tcp.ipfinder.multicast.TcpDiscoveryMulticastIpFinder$AddressSender.body(TcpDiscoveryMulticastIpFinder.java:890)
        at o.a.i.spi.IgniteSpiThread.run(IgniteSpiThread.java:58)

Thread [name="tcp-disco-srvr-[:47500]-#3-#58", id=71, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at java.net.PlainSocketImpl.socketAccept(Native Method)
        at java.net.AbstractPlainSocketImpl.accept(AbstractPlainSocketImpl.java:409)
        at java.net.ServerSocket.implAccept(ServerSocket.java:560)
        at java.net.ServerSocket.accept(ServerSocket.java:528)
        at o.a.i.i.util.IgniteUtils.acceptServerSocket(IgniteUtils.java:12484)
        at o.a.i.spi.discovery.tcp.ServerImpl$TcpServer.body(ServerImpl.java:6595)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at o.a.i.spi.discovery.tcp.ServerImpl$TcpServerThread.body(ServerImpl.java:6518)
        at o.a.i.spi.IgniteSpiThread.run(IgniteSpiThread.java:58)

Thread [name="tcp-disco-msg-worker-[crd]-#2-#57", id=70, state=RUNNABLE, blockCnt=3, waitCnt=315043]
        at sun.management.ThreadImpl.dumpThreads0(Native Method)
        at sun.management.ThreadImpl.dumpAllThreads(ThreadImpl.java:496)
        at sun.management.ThreadImpl.dumpAllThreads(ThreadImpl.java:484)
        at o.a.i.i.util.IgniteUtils.dumpThreads(IgniteUtils.java:1544)
        at o.a.i.i.processors.failure.FailureProcessor.process(FailureProcessor.java:205)
        - locked o.a.i.i.processors.failure.FailureProcessor@790cc521
        at o.a.i.i.processors.failure.FailureProcessor.process(FailureProcessor.java:156)
        at o.a.i.i.IgnitionEx$IgniteNamedInstance$2.apply(IgnitionEx.java:1703)
        at o.a.i.i.IgnitionEx$IgniteNamedInstance$2.apply(IgnitionEx.java:1693)
        at o.a.i.i.worker.WorkersRegistry.onIdle(WorkersRegistry.java:232)
        at o.a.i.i.util.worker.GridWorker.onIdle(GridWorker.java:299)
        at o.a.i.spi.discovery.tcp.ServerImpl$RingMessageWorker.lambda$new$1(ServerImpl.java:2973)
        at o.a.i.spi.discovery.tcp.ServerImpl$RingMessageWorker$$Lambda$549/1386440976.run(Unknown Source)
        at o.a.i.spi.discovery.tcp.ServerImpl$MessageWorker.body(ServerImpl.java:8041)
        at o.a.i.spi.discovery.tcp.ServerImpl$RingMessageWorker.body(ServerImpl.java:3089)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at o.a.i.spi.discovery.tcp.ServerImpl$MessageWorkerThread.body(ServerImpl.java:7979)
        at o.a.i.spi.IgniteSpiThread.run(IgniteSpiThread.java:58)

Thread [name="disco-notifier-worker-#56", id=69, state=WAITING, blockCnt=1, waitCnt=1625]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@61a0433a, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
        at o.a.i.i.managers.discovery.GridDiscoveryManager$DiscoveryMessageNotifierWorker.body0(GridDiscoveryManager.java:2830)
        at o.a.i.i.managers.discovery.GridDiscoveryManager$DiscoveryMessageNotifierWorker.body(GridDiscoveryManager.java:2875)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-data-loader-flusher-#55", id=68, state=WAITING, blockCnt=0, waitCnt=1]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@12499022, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2039)
        at java.util.concurrent.DelayQueue.take(DelayQueue.java:211)
        at o.a.i.i.processors.datastreamer.DataStreamProcessor$2.body(DataStreamProcessor.java:106)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-rest-3-#53", id=66, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@72b978ba
        - locked java.util.Collections$UnmodifiableSet@6d038e01
        - locked sun.nio.ch.EPollSelectorImpl@ed9a908
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-rest-2-#52", id=65, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@504fe071
        - locked java.util.Collections$UnmodifiableSet@690a3e6a
        - locked sun.nio.ch.EPollSelectorImpl@1808c6cc
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-rest-1-#51", id=64, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@5b5abd2c
        - locked java.util.Collections$UnmodifiableSet@7439825e
        - locked sun.nio.ch.EPollSelectorImpl@4cf80bdd
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-rest-0-#50", id=63, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@12988a28
        - locked java.util.Collections$UnmodifiableSet@1c25f68a
        - locked sun.nio.ch.EPollSelectorImpl@2436bc22
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="nio-acceptor-tcp-rest-#54", id=67, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked sun.nio.ch.Util$3@289ced9a
        - locked java.util.Collections$UnmodifiableSet@7e03fb6b
        - locked sun.nio.ch.EPollSelectorImpl@4d21d387
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$GridNioAcceptWorker.accept(GridNioServer.java:3093)
        at o.a.i.i.util.nio.GridNioServer$GridNioAcceptWorker.body(GridNioServer.java:3041)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="long-qry-#42", id=55, state=TIMED_WAITING, blockCnt=0, waitCnt=3216]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.i.util.IgniteUtils.sleep(IgniteUtils.java:8394)
        at o.a.i.i.processors.query.running.HeavyQueriesTracker$1.body(HeavyQueriesTracker.java:104)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="page-lock-tracker-timeout", id=54, state=TIMED_WAITING, blockCnt=0, waitCnt=54]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.i.util.worker.CycleThread.run(CycleThread.java:47)

Thread [name="tcp-comm-worker-#1-#38", id=50, state=TIMED_WAITING, blockCnt=0, waitCnt=6]
    Lock [object=java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject@5ce7a1ad, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:215)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2078)
        at java.util.concurrent.LinkedBlockingQueue.poll(LinkedBlockingQueue.java:467)
        at o.a.i.spi.communication.tcp.internal.CommunicationWorker.body(CommunicationWorker.java:167)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at o.a.i.spi.communication.tcp.TcpCommunicationSpi$3.body(TcpCommunicationSpi.java:848)
        at o.a.i.spi.IgniteSpiThread.run(IgniteSpiThread.java:58)

Thread [name="grid-nio-worker-tcp-comm-5-#36%TcpCommunicationSpi%", id=48, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@13586796
        - locked java.util.Collections$UnmodifiableSet@72611e35
        - locked sun.nio.ch.EPollSelectorImpl@319f5615
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-comm-4-#35%TcpCommunicationSpi%", id=47, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@50146342
        - locked java.util.Collections$UnmodifiableSet@a0ca01
        - locked sun.nio.ch.EPollSelectorImpl@7acaec96
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-comm-3-#34%TcpCommunicationSpi%", id=46, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@31ae2224
        - locked java.util.Collections$UnmodifiableSet@42d34920
        - locked sun.nio.ch.EPollSelectorImpl@442563b9
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-comm-2-#33%TcpCommunicationSpi%", id=45, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@692689f7
        - locked java.util.Collections$UnmodifiableSet@295939f5
        - locked sun.nio.ch.EPollSelectorImpl@719bffb7
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-comm-1-#32%TcpCommunicationSpi%", id=44, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@1e4c7296
        - locked java.util.Collections$UnmodifiableSet@43782999
        - locked sun.nio.ch.EPollSelectorImpl@238e2692
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-nio-worker-tcp-comm-0-#31%TcpCommunicationSpi%", id=43, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked o.a.i.i.util.nio.SelectedSelectionKeySet@dc60313
        - locked java.util.Collections$UnmodifiableSet@706318ff
        - locked sun.nio.ch.EPollSelectorImpl@72d5c38b
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.bodyInternal(GridNioServer.java:2273)
        at o.a.i.i.util.nio.GridNioServer$AbstractNioClientWorker.body(GridNioServer.java:1911)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="nio-acceptor-tcp-comm-#37%TcpCommunicationSpi%", id=49, state=RUNNABLE, blockCnt=0, waitCnt=0]
        at sun.nio.ch.EPollArrayWrapper.epollWait(Native Method)
        at sun.nio.ch.EPollArrayWrapper.poll(EPollArrayWrapper.java:269)
        at sun.nio.ch.EPollSelectorImpl.doSelect(EPollSelectorImpl.java:93)
        at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:86)
        - locked sun.nio.ch.Util$3@203dd1f5
        - locked java.util.Collections$UnmodifiableSet@1dde807a
        - locked sun.nio.ch.EPollSelectorImpl@7512d7de
        at sun.nio.ch.SelectorImpl.select(SelectorImpl.java:97)
        at o.a.i.i.util.nio.GridNioServer$GridNioAcceptWorker.accept(GridNioServer.java:3093)
        at o.a.i.i.util.nio.GridNioServer$GridNioAcceptWorker.body(GridNioServer.java:3041)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="grid-timeout-worker-#30", id=42, state=TIMED_WAITING, blockCnt=3, waitCnt=18265]
    Lock [object=java.lang.Object@29879b6c, ownerName=null, ownerId=-1]
        at java.lang.Object.wait(Native Method)
        at o.a.i.i.processors.timeout.GridTimeoutProcessor$TimeoutWorker.body(GridTimeoutProcessor.java:269)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-11-#24", id=36, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-10-#23", id=35, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-9-#22", id=34, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-8-#21", id=33, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-7-#20", id=32, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-6-#19", id=31, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-5-#18", id=30, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-4-#17", id=29, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-3-#16", id=28, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-2-#15", id=27, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-1-#14", id=26, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="data-streamer-stripe-0-#13", id=25, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-11-#12", id=24, state=WAITING, blockCnt=1, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-10-#11", id=23, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-9-#10", id=22, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-8-#9", id=21, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-7-#8", id=20, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-6-#7", id=19, state=WAITING, blockCnt=0, waitCnt=2]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-5-#6", id=18, state=WAITING, blockCnt=0, waitCnt=2]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-4-#5", id=17, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-3-#4", id=16, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-2-#3", id=15, state=WAITING, blockCnt=0, waitCnt=2]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-1-#2", id=14, state=WAITING, blockCnt=0, waitCnt=1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="sys-stripe-0-#1", id=13, state=WAITING, blockCnt=0, waitCnt=2]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:304)
        at o.a.i.i.util.StripedExecutor$StripeConcurrentQueue.take(StripedExecutor.java:819)
        at o.a.i.i.util.StripedExecutor$Stripe.body(StripedExecutor.java:623)
        at o.a.i.i.util.worker.GridWorker.run(GridWorker.java:125)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="ignite-clock", id=12, state=TIMED_WAITING, blockCnt=0, waitCnt=315547]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.i.util.IgniteUtils$25.run(IgniteUtils.java:3656)
        at java.lang.Thread.run(Thread.java:750)

Thread [name="jvm-pause-detector-worker", id=11, state=TIMED_WAITING, blockCnt=0, waitCnt=64078]
        at java.lang.Thread.sleep(Native Method)
        at o.a.i.i.LongJVMPauseDetector$1.run(LongJVMPauseDetector.java:124)

Thread [name="Signal Dispatcher", id=4, state=RUNNABLE, blockCnt=0, waitCnt=0]

Thread [name="Finalizer", id=3, state=WAITING, blockCnt=9, waitCnt=5]
    Lock [object=java.lang.ref.ReferenceQueue$Lock@677b45d0, ownerName=null, ownerId=-1]
        at java.lang.Object.wait(Native Method)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
        at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
        at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:188)

Thread [name="Reference Handler", id=2, state=WAITING, blockCnt=5, waitCnt=4]
    Lock [object=java.lang.ref.Reference$Lock@ecfd415, ownerName=null, ownerId=-1]
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
        at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)

Thread [name="main", id=1, state=WAITING, blockCnt=3, waitCnt=9]
    Lock [object=java.util.concurrent.CountDownLatch$Sync@6d004e35, ownerName=null, ownerId=-1]
        at sun.misc.Unsafe.park(Native Method)
        at java.util.concurrent.locks.LockSupport.park(LockSupport.java:175)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.parkAndCheckInterrupt(AbstractQueuedSynchronizer.java:836)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:997)
        at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304)
        at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231)
        at o.a.i.startup.cmdline.CommandLineStartup.main(CommandLineStartup.java:398)



[23:34:21,939][WARNING][tcp-disco-msg-worker-[crd]-#2-#57][CacheDiagnosticManager] Page locks dump:





[23:35:59,735][WARNING][jvm-pause-detector-worker][IgniteKernal] Possible too long JVM pause: 92877 milliseconds.
[23:35:59,785][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:21:25.969]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=94MB, free=90.33%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=1, idle=10, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:36:59,793][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:22:25.971]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=97MB, free=90.06%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=6, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:37:59,796][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:23:25.983]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=102MB, free=89.59%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:38:59,801][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:24:25.987]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=104MB, free=89.37%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:39:59,810][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:25:25.994]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=107MB, free=89.07%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:40:59,814][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:26:25.999]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=109MB, free=88.8%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:41:59,818][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:27:26.001]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=112MB, free=88.54%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:42:59,817][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:28:26.001]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=116MB, free=88.1%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:43:59,824][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:29:26.007]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=2]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.1%, GC=0%]
    ^-- Heap [used=119MB, free=87.78%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:44:54,730][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=DynamicCacheChangeBatch [id=de3c9162291-b833fd4c-7c0a-44a3-9bac-3b4e16c7e0df, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=robot_position, hasCfg=true, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[robot_position], stopCaches=null, startGrps=[robot_position], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[23:44:54,736][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=robot_position, id=1677555550, dataRegionName=default, mode=PARTITIONED, atomicity=ATOMIC, backups=0]
[23:44:54,741][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[23:44:54,742][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3]]]]
[23:44:54,742][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], waitTime=0ms, futInfo=NA, mode=LOCAL]
[23:44:54,770][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=3]]
[23:44:54,780][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], err=null, rebalanced=true, wasRebalanced=true]
[23:44:54,785][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=robot_position, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[23:44:54,786][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3]]
[23:44:54,786][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (1 ms), stage="Start caches" (5 ms), stage="Affinity initialization on cache group start" (2 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (1 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (27 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (1 ms), stage="Full message preparing" (5 ms), stage="Full message sending" (0 ms), stage="Exchange done" (6 ms), stage="Total time" (49 ms)]
[23:44:54,787][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], stage="Affinity initialization on cache group start [grp=robot_position]" (2 ms) (parent=Affinity initialization on cache group start)]
[23:44:54,788][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=3], crd=true]
[23:44:54,792][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=3], force=false, evt=DISCOVERY_CUSTOM_EVT, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[23:44:54,792][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=DynamicCacheChangeBatch [id=7f3c9162291-b833fd4c-7c0a-44a3-9bac-3b4e16c7e0df, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=robot_goal, hasCfg=true, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[robot_goal], stopCaches=null, startGrps=[robot_goal], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[23:44:54,795][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=robot_goal, id=-1849376824, dataRegionName=default, mode=PARTITIONED, atomicity=ATOMIC, backups=0]
[23:44:54,802][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[23:44:54,802][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4]]]]
[23:44:54,802][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], waitTime=0ms, futInfo=NA, mode=LOCAL]
[23:44:54,830][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=4]]
[23:44:54,841][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], err=null, rebalanced=true, wasRebalanced=true]
[23:44:54,845][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=robot_goal, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[23:44:54,845][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4]]
[23:44:54,845][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], stage="Waiting in exchange queue" (1 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (3 ms), stage="Affinity initialization on cache group start" (5 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (27 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (0 ms), stage="Apply update counters" (2 ms), stage="Full message preparing" (6 ms), stage="Full message sending" (0 ms), stage="Exchange done" (4 ms), stage="Total time" (48 ms)]
[23:44:54,846][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], stage="Affinity initialization on cache group start [grp=robot_goal]" (5 ms) (parent=Affinity initialization on cache group start)]
[23:44:54,846][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=4], crd=true]
[23:44:54,851][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=4], force=false, evt=DISCOVERY_CUSTOM_EVT, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[23:44:54,924][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=DynamicCacheChangeBatch [id=ef3c9162291-b833fd4c-7c0a-44a3-9bac-3b4e16c7e0df, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=detected_objects, hasCfg=true, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[detected_objects], stopCaches=null, startGrps=[detected_objects], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[23:44:54,925][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=detected_objects, id=-379002793, dataRegionName=default, mode=PARTITIONED, atomicity=ATOMIC, backups=0]
[23:44:54,928][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[23:44:54,928][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5]]]]
[23:44:54,928][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], waitTime=0ms, futInfo=NA, mode=LOCAL]
[23:44:54,941][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=5]]
[23:44:54,949][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], err=null, rebalanced=true, wasRebalanced=true]
[23:44:54,953][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=detected_objects, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[23:44:54,953][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5]]
[23:44:54,953][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (1 ms), stage="Affinity initialization on cache group start" (1 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (12 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (1 ms), stage="Full message preparing" (4 ms), stage="Full message sending" (0 ms), stage="Exchange done" (4 ms), stage="Total time" (24 ms)]
[23:44:54,954][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], stage="Affinity initialization on cache group start [grp=detected_objects]" (1 ms) (parent=Affinity initialization on cache group start)]
[23:44:54,954][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=5], crd=true]
[23:44:54,957][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=5], force=false, evt=DISCOVERY_CUSTOM_EVT, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[23:44:55,029][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=DynamicCacheChangeBatch [id=604c9162291-b833fd4c-7c0a-44a3-9bac-3b4e16c7e0df, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=cmd_smoothed_path, hasCfg=true, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[cmd_smoothed_path], stopCaches=null, startGrps=[cmd_smoothed_path], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[23:44:55,030][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=cmd_smoothed_path, id=-4838382, dataRegionName=default, mode=PARTITIONED, atomicity=ATOMIC, backups=0]
[23:44:55,037][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[23:44:55,038][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6]]]]
[23:44:55,038][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], waitTime=0ms, futInfo=NA, mode=LOCAL]
[23:44:55,055][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=6]]
[23:44:55,063][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], err=null, rebalanced=true, wasRebalanced=true]
[23:44:55,070][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=cmd_smoothed_path, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[23:44:55,070][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6]]
[23:44:55,071][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (2 ms), stage="Affinity initialization on cache group start" (4 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (16 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (2 ms), stage="Full message preparing" (3 ms), stage="Full message sending" (0 ms), stage="Exchange done" (7 ms), stage="Total time" (35 ms)]
[23:44:55,071][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], stage="Affinity initialization on cache group start [grp=cmd_smoothed_path]" (4 ms) (parent=Affinity initialization on cache group start)]
[23:44:55,071][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=6], crd=true]
[23:44:55,076][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=6], force=false, evt=DISCOVERY_CUSTOM_EVT, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[23:44:55,078][INFO][exchange-worker-#63][time] Started exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], crd=true, evt=DISCOVERY_CUSTOM_EVT, evtNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, customEvt=DynamicCacheChangeBatch [id=c04c9162291-b833fd4c-7c0a-44a3-9bac-3b4e16c7e0df, reqs=ArrayList [DynamicCacheChangeRequest [cacheName=subscribed_agents, hasCfg=true, nodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, clientStartOnly=false, stop=false, destroy=false, disabledAfterStart=false]], exchangeActions=ExchangeActions [startCaches=[subscribed_agents], stopCaches=null, startGrps=[subscribed_agents], stopGrps=[], resetParts=null, finalizePartitionCounters=false, stateChangeRequest=null], startCaches=false], allowMerge=false, exchangeFreeSwitch=false]
[23:44:55,080][INFO][exchange-worker-#63][GridCacheProcessor] Started cache [name=subscribed_agents, id=-804153965, dataRegionName=default, mode=PARTITIONED, atomicity=ATOMIC, backups=0]
[23:44:55,083][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], waitTime=0ms, futInfo=NA, mode=DISTRIBUTED]
[23:44:55,083][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partitions release latch: ServerLatch [permits=0, pendingAcks=HashSet [], super=CompletableLatch [id=CompletableLatchUid [id=exchange, topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7]]]]
[23:44:55,083][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finished waiting for partition release future [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], waitTime=0ms, futInfo=NA, mode=LOCAL]
[23:44:55,105][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] finishExchangeOnCoordinator [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=7]]
[23:44:55,120][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Finish exchange future [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], err=null, rebalanced=true, wasRebalanced=true]
[23:44:55,128][INFO][exchange-worker-#63][GridCacheProcessor] Finish proxy initialization, cacheName=subscribed_agents, localNodeId=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b
[23:44:55,128][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Completed partition exchange [localNode=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, exchange=GridDhtPartitionsExchangeFuture [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], evt=DISCOVERY_CUSTOM_EVT, evtNode=TcpDiscoveryNode [id=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b, consistentId=0:0:0:0:0:0:0:1%lo,127.0.0.1,172.22.0.2:47500, addrs=ArrayList [0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], sockAddrs=HashSet [ignite_host/172.22.0.2:47500, /0:0:0:0:0:0:0:1%lo:47500, /127.0.0.1:47500], discPort=47500, order=1, intOrder=1, lastExchangeTime=1727216072147, loc=true, ver=2.16.0#20231215-sha1:7bde6a42, isClient=false], rebalanced=true, done=true, newCrdFut=null], topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7]]
[23:44:55,128][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange timings [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], stage="Waiting in exchange queue" (0 ms), stage="Exchange parameters initialization" (0 ms), stage="Update caches registry" (0 ms), stage="Start caches" (2 ms), stage="Affinity initialization on cache group start" (2 ms), stage="Determine exchange type" (0 ms), stage="Preloading notification" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="Wait partitions release latch [latch=exchange]" (0 ms), stage="Wait partitions release [latch=exchange]" (0 ms), stage="After states restored callback" (21 ms), stage="WAL history reservation" (0 ms), stage="Waiting for all single messages" (0 ms), stage="Affinity recalculation (crd)" (0 ms), stage="Collect update counters and create affinity messages" (0 ms), stage="Assign partitions states" (0 ms), stage="Validate partitions states" (1 ms), stage="Apply update counters" (4 ms), stage="Full message preparing" (8 ms), stage="Full message sending" (0 ms), stage="Exchange done" (8 ms), stage="Total time" (46 ms)]
[23:44:55,129][INFO][exchange-worker-#63][GridDhtPartitionsExchangeFuture] Exchange longest local stages [startVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], resVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], stage="Affinity initialization on cache group start [grp=subscribed_agents]" (2 ms) (parent=Affinity initialization on cache group start)]
[23:44:55,129][INFO][exchange-worker-#63][time] Finished exchange init [topVer=AffinityTopologyVersion [topVer=1, minorTopVer=7], crd=true]
[23:44:55,137][INFO][exchange-worker-#63][GridCachePartitionExchangeManager] Skipping rebalancing (nothing scheduled) [top=AffinityTopologyVersion [topVer=1, minorTopVer=7], force=false, evt=DISCOVERY_CUSTOM_EVT, node=9a74d0ae-7716-4f6d-aa69-ad70646e6d2b]
[23:44:59,830][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:30:26.013]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=4.23%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=164MB, free=83.23%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=12, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:44:59,830][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:45:59,835][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:31:26.017]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=168MB, free=82.79%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:45:59,835][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:46:59,841][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:32:26.026]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.4%, avgLoad=0.11%, GC=0%]
    ^-- Heap [used=275MB, free=71.98%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:46:59,842][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:47:59,846][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:33:26.030]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.23%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=87MB, free=91.11%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=1, idle=6, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:47:59,846][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:48:59,855][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:34:26.042]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=125MB, free=87.18%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:48:59,858][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:49:59,864][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:35:26.050]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.2%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=166MB, free=83%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:49:59,864][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:50:59,868][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:36:26.055]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.3%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=209MB, free=78.66%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:50:59,869][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:51:59,875][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:37:26.058]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.2%, avgLoad=0.12%, GC=0%]
    ^-- Heap [used=246MB, free=74.86%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:51:59,876][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:52:59,876][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:38:26.059]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=289MB, free=70.55%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:52:59,876][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:53:59,879][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:39:26.060]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=62MB, free=93.68%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:53:59,879][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:54:59,876][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:40:26.062]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=103MB, free=89.44%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:54:59,876][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:55:59,885][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:41:26.070]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=145MB, free=85.17%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:55:59,885][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:56:59,892][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:42:26.079]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.17%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=187MB, free=80.87%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:56:59,892][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:57:59,902][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:43:26.088]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=229MB, free=76.61%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:57:59,902][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:58:59,909][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:44:26.096]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=270MB, free=72.41%, comm=981MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:58:59,909][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[23:59:59,917][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:45:26.099]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=60MB, free=93.87%, comm=988MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[23:59:59,917][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[00:00:59,921][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:46:26.102]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.13%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=101MB, free=89.69%, comm=988MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[00:00:59,921][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
[00:01:59,925][INFO][grid-timeout-worker-#30][IgniteKernal] 
Metrics for local node (to disable set 'metricsLogFrequency' to 0)
    ^-- Node [id=9a74d0ae, uptime=01:47:26.110]
    ^-- Cluster [hosts=1, CPUs=12, servers=1, clients=0, topVer=1, minorTopVer=7]
    ^-- Network [addrs=[0:0:0:0:0:0:0:1%lo, 127.0.0.1, 172.22.0.2], discoPort=47500, commPort=47100]
    ^-- CPU [CPUs=12, curLoad=0.1%, avgLoad=0.13%, GC=0%]
    ^-- Heap [used=120MB, free=87.82%, comm=988MB]
    ^-- Outbound messages queue [size=0]
    ^-- Public thread pool [active=0, idle=0, qSize=0]
    ^-- System thread pool [active=0, idle=7, qSize=0]
    ^-- Striped thread pool [active=0, idle=12, qSize=0]
[00:01:59,926][INFO][grid-timeout-worker-#30][IgniteKernal] FreeList [name=default##FreeList, buckets=256, dataPages=1, reusePages=0]
